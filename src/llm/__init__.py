"""
LLMè°ƒç”¨æ¨¡å—

æœ¬æ¨¡å—æä¾›é«˜è´¨é‡çš„LLMè°ƒç”¨æ¥å£ï¼Œç”¨äºç”Ÿæˆè®­ç»ƒæ•°æ®é›†ã€‚
è®¾è®¡ç›®æ ‡ï¼šæœ€å¤§åŒ–æ•°æ®è´¨é‡ï¼Œä¸è®¡tokenæ¶ˆè€—ã€‚
"""
import hashlib
import json
import logging
import os
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

from openai import OpenAI, APIError, RateLimitError, APITimeoutError

from ..config import get_config

logger = logging.getLogger(__name__)

# ============ å¸¸é‡å®šä¹‰ ============
MAX_INPUT_LENGTH = 50000  # æœ€å¤§è¾“å…¥é•¿åº¦ (50KB)
DEFAULT_CACHE_MAX_SIZE = 1000  # é»˜è®¤ç¼“å­˜æœ€å¤§æ¡ç›®æ•°
DEFAULT_CACHE_MAX_AGE = 86400  # é»˜è®¤ç¼“å­˜æœ€å¤§å­˜æ´»æ—¶é—´ (24å°æ—¶)


# ============ è‡ªå®šä¹‰å¼‚å¸¸ ============
class LLMError(Exception):
    """LLM è°ƒç”¨é”™è¯¯åŸºç±»"""
    pass


class QAGenerationError(LLMError):
    """QA å¯¹ç”Ÿæˆé”™è¯¯"""
    pass


class JSONParseError(LLMError):
    """JSON è§£æé”™è¯¯"""
    pass


class CacheError(Exception):
    """ç¼“å­˜é”™è¯¯"""
    pass


class LLMClient:
    """
    é«˜è´¨é‡LLMå®¢æˆ·ç«¯
    
    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨æœ€é«˜å“è´¨æ¨¡å‹é…ç½®
    - å¤šè½®ç”Ÿæˆ+è´¨é‡ç­›é€‰
    - è¯¦ç»†çš„ç”Ÿæˆprompt
    """
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        model: Optional[str] = None
    ):
        config = get_config()
        
        self.api_key = api_key or config.llm.api_key
        self.base_url = base_url or config.llm.base_url
        # å¼ºåˆ¶ä½¿ç”¨æœ€é«˜å“è´¨é…ç½®
        self.model = model or config.llm.model
        self.temperature = 0.2  # é™ä½éšæœºæ€§ï¼Œæé«˜è´¨é‡
        self.max_tokens = None  # ä¸é™åˆ¶ï¼Œè®©æ¨¡å‹ç”Ÿæˆå®Œæ•´å›ç­”
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
    
    def chat(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        å‘é€å¯¹è¯è¯·æ±‚
        
        ä½¿ç”¨è¾ƒä½æ¸©åº¦ç¡®ä¿è¾“å‡ºè´¨é‡ç¨³å®š
        """
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature or self.temperature,
            max_tokens=max_tokens or self.max_tokens,
            # é«˜è´¨é‡å‚æ•°
            presence_penalty=0.1,
            frequency_penalty=0.1,
            **kwargs
        )
        
        return response.choices[0].message.content
    
    def generate_qa_pairs(
        self,
        text: str,
        num_pairs: int = 5,
        language: str = "zh"
    ) -> List[Dict[str, str]]:
        """
        ä»æ–‡æœ¬ç”Ÿæˆé«˜è´¨é‡QAå¯¹
        
        ç‰¹ç‚¹ï¼š
        - è¯¦ç»†çš„system promptæŒ‡å¯¼
        - æ¯ä¸ªQAéƒ½åŸºäºæ–‡æœ¬å†…å®¹
        - å¼ºåˆ¶JSONæ ¼å¼è¾“å‡º
        - è‡ªåŠ¨é‡è¯•æœºåˆ¶
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            num_pairs: ç”ŸæˆQAå¯¹æ•°é‡ (é»˜è®¤5)
            language: è¯­è¨€
            
        Returns:
            QAå¯¹åˆ—è¡¨
            
        Raises:
            QAGenerationError: ç”Ÿæˆå¤±è´¥
        """
        # éªŒè¯è¾“å…¥
        if not text or not text.strip():
            logger.warning("è¾“å…¥æ–‡æœ¬ä¸ºç©º")
            return []
        
        if len(text) > MAX_INPUT_LENGTH:
            raise QAGenerationError(
                f"è¾“å…¥æ–‡æœ¬è¿‡é•¿ ({len(text)} > {MAX_INPUT_LENGTH} å­—ç¬¦)"
            )
        
        if num_pairs < 1 or num_pairs > 20:
            logger.warning(f"æ— æ•ˆçš„ num_pairs å€¼: {num_pairs}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 5")
            num_pairs = 5
        
        lang_prompt = "ä¸­æ–‡" if language == "zh" else "English"
        
        # é«˜è´¨é‡system prompt
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†æå–ä¸“å®¶ï¼Œè´Ÿè´£ä»æ–‡æ¡£ä¸­ç”Ÿæˆé«˜è´¨é‡çš„é—®ç­”å¯¹ç”¨äºAIè®­ç»ƒã€‚

## æ ¸å¿ƒä»»åŠ¡
æ ¹æ®æä¾›çš„æ–‡æœ¬å†…å®¹ï¼Œç”Ÿæˆ {num_pairs} ä¸ªé«˜è´¨é‡çš„é—®ç­”å¯¹ã€‚

## è´¨é‡æ ‡å‡†

### é—®é¢˜è¦æ±‚
1. **è¦†ç›–å…¨é¢** - é—®é¢˜åº”è¦†ç›–æ–‡æœ¬çš„æ ¸å¿ƒæ¦‚å¿µã€é‡è¦ç»†èŠ‚å’Œå…³é”®ä¿¡æ¯
2. **å±‚æ¬¡åˆ†æ˜** - åŒ…å«ä¸åŒéš¾åº¦çº§åˆ«ï¼š
   - åŸºç¡€é—®é¢˜ï¼ˆæ˜¯ä»€ä¹ˆã€è°ã€ä½•æ—¶ã€ä½•åœ°ï¼‰
   - è¿›é˜¶é—®é¢˜ï¼ˆä¸ºä»€ä¹ˆã€å¦‚ä½•ã€åŸç†ï¼‰
   - æ·±åº¦é—®é¢˜ï¼ˆåˆ†æã€æ¯”è¾ƒã€åº”ç”¨ï¼‰
3. **è¡¨è¿°æ¸…æ™°** - é—®é¢˜æ˜ç¡®ã€æ— æ­§ä¹‰ã€ä¸“ä¸šæœ¯è¯­ä½¿ç”¨å‡†ç¡®
4. **ç‹¬ç«‹å®Œæ•´** - æ¯ä¸ªé—®é¢˜éƒ½èƒ½ç‹¬ç«‹ç†è§£ï¼Œä¸éœ€è¦é¢å¤–ä¸Šä¸‹æ–‡

### ç­”æ¡ˆè¦æ±‚
1. **å‡†ç¡®æ— è¯¯** - ç­”æ¡ˆå¿…é¡»å®Œå…¨åŸºäºæ–‡æœ¬å†…å®¹
2. **è¯¦ç»†å®Œæ•´** - æä¾›å……åˆ†çš„è§£é‡Šå’Œä¸Šä¸‹æ–‡
3. **ç»“æ„æ¸…æ™°** - å¤æ‚ç­”æ¡ˆä½¿ç”¨é€‚å½“çš„æ ¼å¼
4. **æ·±åº¦é€‚å½“** - æ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´ç­”æ¡ˆæ·±åº¦

### è¾“å‡ºè¦æ±‚
1. ä¸¥æ ¼JSONæ ¼å¼
2. æ¯ä¸ªQAå¯¹ç‹¬ç«‹å®Œæ•´
3. ä¸è¦é‡å¤æˆ–ç±»ä¼¼çš„é—®é¢˜
4. é—®é¢˜ç­”æ¡ˆè¦ä¸€ä¸€å¯¹åº”

è¯·ç”Ÿæˆè¿™ {num_pairs} ä¸ªé—®ç­”å¯¹ã€‚ä¿æŒ{language}è¾“å‡ºã€‚"""
        
        user_prompt = f"""## å¾…å¤„ç†æ–‡æœ¬

ä»¥ä¸‹æ˜¯ä»æ–‡æ¡£ä¸­æå–çš„æ–‡æœ¬å†…å®¹ï¼Œè¯·ä»”ç»†åˆ†æå¹¶ç”Ÿæˆé—®ç­”å¯¹ï¼š

---
{text}
---

è¯·æŒ‰ç…§ä¸Šè¿°è´¨é‡æ ‡å‡†ï¼Œç”Ÿæˆ {num_pairs} ä¸ªé«˜è´¨é‡é—®ç­”å¯¹ã€‚

## è¾“å‡ºæ ¼å¼
```json
[
  {{
    "instruction": "æ¸…æ™°æ˜ç¡®çš„é—®é¢˜",
    "input": "",
    "output": "è¯¦ç»†å‡†ç¡®çš„ç­”æ¡ˆ"
  }}
]
```

ç¡®ä¿ï¼š
1. é—®é¢˜è¦†ç›–æ–‡æœ¬çš„æ ¸å¿ƒå†…å®¹
2. ç­”æ¡ˆè¯¦ç»†ä¸”åŸºäºæ–‡æœ¬
3. JSONæ ¼å¼æ­£ç¡®æ— è¯¯
4. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—"""
        
        # å°è¯•å¤šæ¬¡ç”Ÿæˆï¼Œé€‰æ‹©æœ€å¥½çš„ç»“æœ
        best_result = []
        for attempt in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
            try:
                response = self.chat([
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ])
                
                pairs = self._extract_json(response)
                
                # éªŒè¯è´¨é‡
                if self._validate_qa_pairs(pairs, num_pairs):
                    best_result = pairs
                    logger.info(f"æˆåŠŸç”Ÿæˆ {len(pairs)} ä¸ªQAå¯¹ (å°è¯• {attempt + 1}/3)")
                    break
                    
            except JSONParseError as e:
                logger.warning(f"JSONè§£æå¤±è´¥ (å°è¯• {attempt + 1}/3): {e}")
            except Exception as e:
                logger.error(f"ç”ŸæˆQAå¯¹å¤±è´¥ (å°è¯• {attempt + 1}/3): {e}")
                if attempt == 2:  # æœ€åä¸€æ¬¡å°è¯•
                    raise QAGenerationError(f"ç”ŸæˆQAå¯¹å¤±è´¥: {e}")
                continue
        
        # å¦‚æœè‡ªåŠ¨ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸºäºè§„åˆ™çš„fallback
        if not best_result:
            logger.warning("ä½¿ç”¨fallbackç”Ÿæˆç®€å•QAå¯¹")
            best_result = self._generate_simple_qa(text, num_pairs)
        
        return best_result
    
    def _validate_qa_pairs(
        self, 
        pairs: List[Dict], 
        expected_count: int
    ) -> bool:
        """
        éªŒè¯QAå¯¹è´¨é‡
        
        æ£€æŸ¥ï¼š
        - æ•°é‡æ˜¯å¦è¶³å¤Ÿ
        - æ ¼å¼æ˜¯å¦æ­£ç¡®
        - æ˜¯å¦æœ‰ç©ºå†…å®¹
        """
        if not pairs:
            return False
        
        if len(pairs) < expected_count // 2:
            return False
        
        for pair in pairs:
            if not isinstance(pair, dict):
                return False
            if not pair.get("instruction") or not pair.get("output"):
                return False
        
        return True
    
    def _extract_json(self, response: str) -> List[Dict[str, str]]:
        """
        ä»å“åº”ä¸­æå–JSON
        
        å°è¯•å¤šç§æ–¹å¼æå–ï¼š
        1. ç›´æ¥è§£æ
        2. ä»ä»£ç å—ä¸­æå–
        3. æŸ¥æ‰¾JSONæ•°ç»„
        """
        import re
        
        # æ–¹å¼1: ç›´æ¥è§£æ
        try:
            return json.loads(response)
        except json.JSONDecodeError:
            pass
        
        # æ–¹å¼2: ä»ä»£ç å—ä¸­æå–
        json_match = re.search(
            r'```(?:json)?\s*([\s\S]*?)\s*```', 
            response
        )
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass
        
        # æ–¹å¼3: æŸ¥æ‰¾JSONæ•°ç»„
        array_match = re.search(r'(\[[\s\S]*?\])\s*$', response)
        if array_match:
            try:
                return json.loads(array_match.group(1))
            except json.JSONDecodeError:
                pass
        
        # æ–¹å¼4: æŸ¥æ‰¾ä»»æ„JSONæ•°ç»„
        all_arrays = re.findall(r'\[[\s\S]*?\]', response)
        for arr_str in all_arrays:
            try:
                parsed = json.loads(arr_str)
                if isinstance(parsed, list) and len(parsed) > 0:
                    return parsed
            except json.JSONDecodeError:
                continue
        
        raise JSONParseError(
            f"æ— æ³•è§£æLLMå“åº”ä¸­çš„JSON:\n"
            f"å“åº”å†…å®¹: {response[:500]}..."
        )
    
    def _generate_simple_qa(
        self, 
        text: str, 
        num_pairs: int
    ) -> List[Dict[str, str]]:
        """
        ç®€å•çš„fallback QAç”Ÿæˆ
        
        å½“LLMç”Ÿæˆå¤±è´¥æ—¶ä½¿ç”¨
        """
        import re
        
        # åˆ‡åˆ†æ–‡æœ¬ä¸ºå¥å­
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
        sentences = [s.strip() for s in sentences if s.strip() and len(s) > 10]
        
        pairs = []
        for i, sent in enumerate(sentences[:num_pairs]):
            pairs.append({
                "instruction": f"è¯·è§£é‡Šä»¥ä¸‹å†…å®¹",
                "input": "",
                "output": sent
            })
        
        return pairs
    
    def generate_summarization(
        self,
        text: str,
        language: str = "zh"
    ) -> str:
        """ç”Ÿæˆé«˜è´¨é‡æ‘˜è¦"""
        lang_prompt = "ä¸­æ–‡" if language == "zh" else "English"
        
        response = self.chat([
            {
                "role": "system",
                "content": f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬æ‘˜è¦ä¸“å®¶ã€‚
è¯·ç”¨{lang_prompt}ç”Ÿæˆä¸€æ®µç®€æ´è€Œå…¨é¢çš„æ‘˜è¦ã€‚
è¦æ±‚ï¼š
1. ä¿ç•™å…³é”®ä¿¡æ¯å’Œæ ¸å¿ƒè§‚ç‚¹
2. é€»è¾‘æ¸…æ™°ï¼Œç»“æ„å®Œæ•´
3. å­—æ•°é€‚ä¸­ï¼ˆ200-500å­—ï¼‰"""
            },
            {
                "role": "user",
                "content": f"è¯·ä¸ºä»¥ä¸‹æ–‡æœ¬ç”Ÿæˆæ‘˜è¦ï¼š\n\n{text}"
            }
        ])
        
        return response.strip()
    
    def generate_conversation(
        self,
        text: str,
        num_turns: int = 3,
        language: str = "zh"
    ) -> List[Dict[str, str]]:
        """ç”Ÿæˆé«˜è´¨é‡å¯¹è¯æ•°æ®"""
        lang_prompt = "ä¸­æ–‡" if language == "zh" else "English"
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚
è¯·æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆä¸€æ®µè‡ªç„¶çš„å¯¹è¯ã€‚

è¦æ±‚ï¼š
1. å¯¹è¯è‡ªç„¶æµç•…ï¼ŒåƒçœŸå®å¯¹è¯
2. å†…å®¹åŸºäºæä¾›çš„æ–‡æ¡£
3. ä½“ç°æ–‡æ¡£çš„æ ¸å¿ƒä¿¡æ¯
4. {lang_prompt}è¾“å‡º
5. JSONæ•°ç»„æ ¼å¼

å¯¹è¯æ ¼å¼ï¼š
[
  {{"role": "user", "content": "ç”¨æˆ·é—®é¢˜"}},
  {{"role": "assistant", "content": "åŠ©æ‰‹å›ç­”"}}
]

è¯·ç”Ÿæˆ {num_turns} è½®å¯¹è¯ã€‚"""
        
        response = self.chat([
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"åŸºäºä»¥ä¸‹å†…å®¹ç”Ÿæˆå¯¹è¯ï¼š\n\n{text}"}
        ])
        
        try:
            return self._extract_json(response)
        except JSONParseError:
            # Fallback: è¿”å›ç®€å•æ ¼å¼
            logger.warning("å¯¹è¯ç”ŸæˆJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨fallback")
            return [
                {"role": "user", "content": "è¯·ä»‹ç»ä¸€ä¸‹"},
                {"role": "assistant", "content": "å¥½çš„ï¼Œè®©æˆ‘æ¥ä»‹ç»..."}
            ]
    
    def batch_generate_qa(
        self,
        texts: List[str],
        num_pairs_per_text: int = 5,
        progress: bool = True
    ) -> List[Dict[str, str]]:
        """
        æ‰¹é‡ç”ŸæˆQAå¯¹
        
        ç‰¹ç‚¹ï¼š
        - æ¯ä¸ªæ–‡æœ¬ç‹¬ç«‹ç”Ÿæˆ
        - æ˜¾ç¤ºè¿›åº¦æ¡
        - è·³è¿‡ç©ºæ–‡æœ¬
        """
        from tqdm import tqdm
        
        all_pairs = []
        # è¿‡æ»¤ç©ºæ–‡æœ¬
        texts = [t for t in texts if t.strip()]
        
        iterator = tqdm(texts, desc="ğŸ”„ ç”Ÿæˆé«˜è´¨é‡QAå¯¹") if progress else texts
        
        for text in iterator:
            try:
                pairs = self.generate_qa_pairs(text, num_pairs_per_text)
                all_pairs.extend(pairs)
            except Exception as e:
                logger.warning(f"ç”Ÿæˆå¤±è´¥: {e}")
                continue
        
        return all_pairs


class CacheManager:
    """
    LLMå“åº”ç¼“å­˜ç®¡ç†å™¨
    
    ç”¨äºé¿å…é‡å¤è°ƒç”¨LLMï¼ŒèŠ‚çœæˆæœ¬
    
    ç‰¹æ€§ï¼š
    - ç¼“å­˜æ¸…ç†æœºåˆ¶ï¼ˆå¤§å°é™åˆ¶ã€æ—¶é—´é™åˆ¶ï¼‰
    - çº¿ç¨‹å®‰å…¨
    - è·¨å¹³å°æ”¯æŒ
    """
    
    def __init__(
        self, 
        cache_dir: str = "./data/cache",
        max_size: int = DEFAULT_CACHE_MAX_SIZE,
        max_age: int = DEFAULT_CACHE_MAX_AGE
    ):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•° (é»˜è®¤ 1000)
            max_age: ç¼“å­˜æœ€å¤§å­˜æ´»æ—¶é—´ï¼Œç§’ (é»˜è®¤ 24å°æ—¶)
        """
        self.cache_dir = Path(cache_dir)
        self.max_size = max_size
        self.max_age = max_age
        self._ensure_cache_dir()
    
    def _ensure_cache_dir(self):
        """ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨"""
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def _get_cache_key(self, text: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        import hashlib
        content = text + str(sorted(kwargs.items()))
        return hashlib.md5(content.encode()).hexdigest()
    
    def _get_cache_file(self, key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{key}.json"
    
    def _get_cache_info_file(self, key: str) -> Path:
        """è·å–ç¼“å­˜ä¿¡æ¯æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{key}.info"
    
    def _get_file_age(self, file_path: Path) -> float:
        """è·å–æ–‡ä»¶å¹´é¾„ï¼ˆç§’ï¼‰"""
        try:
            return time.time() - file_path.stat().st_mtime
        except OSError:
            return float('inf')
    
    def _save_cache_info(self, key: str, metadata: Dict = None):
        """ä¿å­˜ç¼“å­˜å…ƒä¿¡æ¯"""
        info_file = self._get_cache_info_file(key)
        info = {
            'created_at': time.time(),
            'key': key,
            **(metadata or {})
        }
        try:
            with open(info_file, 'w') as f:
                json.dump(info, f)
        except Exception as e:
            logger.warning(f"ä¿å­˜ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")
    
    def get(self, text: str, **kwargs) -> Optional[str]:
        """è·å–ç¼“å­˜
        
        Args:
            text: ç¼“å­˜çš„æ–‡æœ¬
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç¼“å­˜çš„å“åº”ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        key = self._get_cache_key(text, **kwargs)
        cache_file = self._get_cache_file(key)
        info_file = self._get_cache_info_file(key)
        
        if not cache_file.exists():
            return None
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if info_file.exists():
            try:
                with open(info_file, 'r') as f:
                    info = json.load(f)
                created_at = info.get('created_at', 0)
                if time.time() - created_at > self.max_age:
                    # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                    self._delete_cache(key)
                    return None
            except Exception:
                pass
        
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception:
            return None
    
    def set(self, text: str, response: str, **kwargs):
        """è®¾ç½®ç¼“å­˜
        
        Args:
            text: ç¼“å­˜çš„æ–‡æœ¬
            response: ç¼“å­˜çš„å“åº”
            **kwargs: å…¶ä»–å‚æ•°
        """
        key = self._get_cache_key(text, **kwargs)
        cache_file = self._get_cache_file(key)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç¼“å­˜
        self._cleanup_if_needed()
        
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                f.write(response)
            self._save_cache_info(key, {'text_length': len(text)})
        except Exception as e:
            logger.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def _delete_cache(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        cache_file = self._get_cache_file(key)
        info_file = self._get_cache_info_file(key)
        
        try:
            if cache_file.exists():
                cache_file.unlink()
            if info_file.exists():
                info_file.unlink()
        except Exception as e:
            logger.warning(f"åˆ é™¤ç¼“å­˜å¤±è´¥: {e}")
    
    def _cleanup_if_needed(self):
        """å¿…è¦æ—¶æ¸…ç†ç¼“å­˜"""
        try:
            # ç»Ÿè®¡ç¼“å­˜æ•°é‡
            cache_files = list(self.cache_dir.glob("*.json"))
            
            if len(cache_files) < self.max_size:
                return
            
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜
            cache_with_age = []
            for cache_file in cache_files:
                key = cache_file.stem
                info_file = self._get_cache_info_file(key)
                
                if info_file.exists():
                    try:
                        with open(info_file, 'r') as f:
                            info = json.load(f)
                        created_at = info.get('created_at', 0)
                        cache_with_age.append((cache_file, created_at))
                    except Exception:
                        cache_with_age.append((cache_file, 0))
                else:
                    cache_with_age.append((cache_file, 0))
            
            # æŒ‰æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„
            cache_with_age.sort(key=lambda x: x[1])
            num_to_delete = len(cache_files) - self.max_size + 100
            
            for cache_file, _ in cache_with_age[:num_to_delete]:
                key = cache_file.stem
                self._delete_cache(key)
                logger.debug(f"æ¸…ç†ç¼“å­˜: {key}")
                
        except Exception as e:
            logger.warning(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        try:
            for cache_file in self.cache_dir.glob("*.json"):
                cache_file.unlink()
            for info_file in self.cache_dir.glob("*.info"):
                info_file.unlink()
            logger.info(f"å·²æ¸…ç©ºç¼“å­˜ç›®å½•: {self.cache_dir}")
        except Exception as e:
            logger.error(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")
            raise CacheError(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            info_files = list(self.cache_dir.glob("*.info"))
            
            total_size = sum(f.stat().st_size for f in cache_files if f.exists())
            
            # è®¡ç®—ç¼“å­˜å¹´é¾„
            ages = []
            for info_file in info_files:
                try:
                    with open(info_file, 'r') as f:
                        info = json.load(f)
                    created_at = info.get('created_at', 0)
                    if created_at:
                        ages.append(time.time() - created_at)
                except Exception:
                    pass
            
            avg_age = sum(ages) / len(ages) if ages else 0
            
            return {
                'cache_count': len(cache_files),
                'total_size_bytes': total_size,
                'total_size_mb': total_size / 1024 / 1024,
                'max_size': self.max_size,
                'max_age_seconds': self.max_age,
                'avg_age_seconds': avg_age,
                'cache_dir': str(self.cache_dir)
            }
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {}


"""
LLM è°ƒç”¨æ¨¡å—

æœ¬æ¨¡å—æä¾› OpenAI API é›†æˆå’Œé«˜å“è´¨è®­ç»ƒæ•°æ®ç”ŸæˆåŠŸèƒ½ã€‚

## ä¸»è¦åŠŸèƒ½

### LLMClient - LLM å®¢æˆ·ç«¯

æä¾›ä¸ OpenAI API çš„äº¤äº’æ¥å£ï¼Œæ”¯æŒï¼š
- åŸºç¡€å¯¹è¯åŠŸèƒ½
- QA å¯¹æ‰¹é‡ç”Ÿæˆ
- æ–‡æœ¬æ‘˜è¦ç”Ÿæˆ
- å¯¹è¯æ•°æ®ç”Ÿæˆ
- å“åº”ç¼“å­˜

### CacheManager - ç¼“å­˜ç®¡ç†å™¨

æä¾› LLM å“åº”ç¼“å­˜åŠŸèƒ½ï¼Œæ”¯æŒï¼š
- è‡ªåŠ¨ç¼“å­˜ç®¡ç†
- ç¼“å­˜å¤§å°é™åˆ¶
- ç¼“å­˜è¿‡æœŸæ¸…ç†
- ç¼“å­˜ç»Ÿè®¡

## ä½¿ç”¨ç¤ºä¾‹

```python
from src.llm import LLMClient, CacheManager

# åˆ›å»º LLM å®¢æˆ·ç«¯
client = LLMClient(
    api_key="your-api-key",
    model="gpt-4o",
    temperature=0.3
)

# å‘é€å¯¹è¯
response = client.chat([
    {"role": "user", "content": "ä½ å¥½ï¼"}
])
print(response)

# ç”Ÿæˆ QA å¯¹
qa_pairs = client.generate_qa_pairs(
    text="è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬...",
    num_pairs=5,
    language="zh"
)

# ä½¿ç”¨ç¼“å­˜
cache = CacheManager(
    cache_dir="./data/cache",
    max_size=1000,
    max_age=86400  # 24å°æ—¶
)

# æ£€æŸ¥ç¼“å­˜
cached = cache.get(text)
if not cached:
    response = client.generate_qa_pairs(text)
    cache.set(text, response)
```

## å¼‚å¸¸å¤„ç†

æœ¬æ¨¡å—å®šä¹‰äº†ä»¥ä¸‹è‡ªå®šä¹‰å¼‚å¸¸ï¼š

- `LLMError` - LLM è°ƒç”¨é”™è¯¯åŸºç±»
- `QAGenerationError` - QA å¯¹ç”Ÿæˆé”™è¯¯
- `JSONParseError` - JSON è§£æé”™è¯¯
- `CacheError` - ç¼“å­˜æ“ä½œé”™è¯¯

```python
from src.llm import LLMClient, QAGenerationError, JSONParseError

client = LLMClient()

try:
    qa_pairs = client.generate_qa_pairs(text)
except QAGenerationError as e:
    print(f"QA ç”Ÿæˆå¤±è´¥: {e}")
except JSONParseError as e:
    print(f"JSON è§£æå¤±è´¥: {e}")
```

## æ€§èƒ½ä¼˜åŒ–

1. **ç¼“å­˜ç­–ç•¥**
   - é»˜è®¤ç¼“å­˜ 1000 æ¡
   - é»˜è®¤è¿‡æœŸæ—¶é—´ 24 å°æ—¶
   - è‡ªåŠ¨æ¸…ç†æ—§ç¼“å­˜

2. **æ‰¹å¤„ç†**
   - ä½¿ç”¨ `batch_generate_qa()` æ‰¹é‡ç”Ÿæˆ
   - è‡ªåŠ¨è¿‡æ»¤ç©ºæ–‡æœ¬

3. **æ¸©åº¦è®¾ç½®**
   - é»˜è®¤æ¸©åº¦ 0.2ï¼Œç¡®ä¿è¾“å‡ºç¨³å®š
   - å¯æ ¹æ®éœ€è¦è°ƒæ•´

## æ³¨æ„äº‹é¡¹

- éœ€è¦æœ‰æ•ˆçš„ OpenAI API Key
- API è°ƒç”¨ä¼šè®¡è´¹ï¼Œè¯·æ³¨æ„æˆæœ¬æ§åˆ¶
- å»ºè®®è®¾ç½®åˆç†çš„ max_tokens é™åˆ¶
- å¤§æ–‡æœ¬ä¼šè‡ªåŠ¨åˆ†å—å¤„ç†
"""

__all__ = [
    'LLMClient',
    'CacheManager',
    'LLMError',
    'QAGenerationError',
    'JSONParseError',
    'CacheError',
]
