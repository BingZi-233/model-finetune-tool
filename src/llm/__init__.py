"""
LLMè°ƒç”¨æ¨¡å—

æœ¬æ¨¡å—æä¾›é«˜è´¨é‡çš„LLMè°ƒç”¨æ¥å£ï¼Œç”¨äºç”Ÿæˆè®­ç»ƒæ•°æ®é›†ã€‚
è®¾è®¡ç›®æ ‡ï¼šæœ€å¤§åŒ–æ•°æ®è´¨é‡ï¼Œä¸è®¡tokenæ¶ˆè€—ã€‚
"""

import hashlib
import json
import logging
import os
import sys
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

from openai import OpenAI, APIError, RateLimitError, APITimeoutError

from ..config import get_config

logger = logging.getLogger(__name__)

# ============ å¸¸é‡å®šä¹‰ ============
MAX_INPUT_LENGTH = 50000  # æœ€å¤§è¾“å…¥é•¿åº¦ (50KB)
DEFAULT_CACHE_MAX_SIZE = 1000  # é»˜è®¤ç¼“å­˜æœ€å¤§æ¡ç›®æ•°
DEFAULT_CACHE_MAX_AGE = 86400  # é»˜è®¤ç¼“å­˜æœ€å¤§å­˜æ´»æ—¶é—´ (24å°æ—¶)


# ============ è‡ªå®šä¹‰å¼‚å¸¸ ============
class LLMError(Exception):
    """LLM è°ƒç”¨é”™è¯¯åŸºç±»"""

    pass


class QAGenerationError(LLMError):
    """QA å¯¹ç”Ÿæˆé”™è¯¯"""

    pass


class JSONParseError(LLMError):
    """JSON è§£æé”™è¯¯"""

    pass


class CacheError(Exception):
    """ç¼“å­˜é”™è¯¯"""

    pass


class LLMClient:
    """
    é«˜è´¨é‡LLMå®¢æˆ·ç«¯

    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨æœ€é«˜å“è´¨æ¨¡å‹é…ç½®
    - å¤šè½®ç”Ÿæˆ+è´¨é‡ç­›é€‰
    - è¯¦ç»†çš„ç”Ÿæˆprompt
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        model: Optional[str] = None,
    ):
        config = get_config()

        self.api_key = api_key or config.llm.api_key
        self.base_url = base_url or config.llm.base_url
        # å¼ºåˆ¶ä½¿ç”¨æœ€é«˜å“è´¨é…ç½®
        self.model = model or config.llm.model
        self.temperature = 0.2  # é™ä½éšæœºæ€§ï¼Œæé«˜è´¨é‡
        self.max_tokens = None  # ä¸é™åˆ¶ï¼Œè®©æ¨¡å‹ç”Ÿæˆå®Œæ•´å›ç­”

        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)

    def chat(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        json_mode: bool = False,
        **kwargs,
    ) -> str:
        """
        å‘é€å¯¹è¯è¯·æ±‚

        ä½¿ç”¨è¾ƒä½æ¸©åº¦ç¡®ä¿è¾“å‡ºè´¨é‡ç¨³å®š

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            json_mode: æ˜¯å¦å¼ºåˆ¶JSONæ ¼å¼å“åº”
            **kwargs: å…¶ä»–å‚æ•°
        """
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature or self.temperature,
            "max_tokens": max_tokens or self.max_tokens,
            "presence_penalty": 0.1,
            "frequency_penalty": 0.1,
            **kwargs,
        }

        # å¦‚æœéœ€è¦JSONå“åº”ï¼Œæ·»åŠ response_format
        if json_mode:
            request_params["response_format"] = {"type": "json_object"}

        response = self.client.chat.completions.create(**request_params)

        return response.choices[0].message.content

    def generate_qa_pairs(
        self, text: str, num_pairs: int = 5, language: str = "zh"
    ) -> List[Dict[str, str]]:
        """
        ä»æ–‡æœ¬ç”Ÿæˆé«˜è´¨é‡QAå¯¹

        ç‰¹ç‚¹ï¼š
        - è¯¦ç»†çš„system promptæŒ‡å¯¼
        - æ¯ä¸ªQAéƒ½åŸºäºæ–‡æœ¬å†…å®¹
        - å¼ºåˆ¶JSONæ ¼å¼è¾“å‡º
        - è‡ªåŠ¨é‡è¯•æœºåˆ¶

        Args:
            text: è¾“å…¥æ–‡æœ¬
            num_pairs: ç”ŸæˆQAå¯¹æ•°é‡ (é»˜è®¤5)
            language: è¯­è¨€

        Returns:
            QAå¯¹åˆ—è¡¨

        Raises:
            QAGenerationError: ç”Ÿæˆå¤±è´¥
        """
        # éªŒè¯è¾“å…¥
        if not text or not text.strip():
            logger.warning("è¾“å…¥æ–‡æœ¬ä¸ºç©º")
            return []

        if len(text) > MAX_INPUT_LENGTH:
            raise QAGenerationError(
                f"è¾“å…¥æ–‡æœ¬è¿‡é•¿ ({len(text)} > {MAX_INPUT_LENGTH} å­—ç¬¦)"
            )

        if num_pairs < 1 or num_pairs > 20:
            logger.warning(f"æ— æ•ˆçš„ num_pairs å€¼: {num_pairs}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 5")
            num_pairs = 5

        lang_prompt = "ä¸­æ–‡" if language == "zh" else "English"

        # é«˜è´¨é‡system prompt
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†æå–ä¸“å®¶ï¼Œè´Ÿè´£ä»æ–‡æ¡£ä¸­ç”Ÿæˆé«˜è´¨é‡çš„é—®ç­”å¯¹ç”¨äºAIè®­ç»ƒã€‚

## æ ¸å¿ƒä»»åŠ¡
æ ¹æ®æä¾›çš„æ–‡æœ¬å†…å®¹ï¼Œç”Ÿæˆ {num_pairs} ä¸ªé«˜è´¨é‡çš„é—®ç­”å¯¹ã€‚

## è´¨é‡æ ‡å‡†

### é—®é¢˜è¦æ±‚
1. **è¦†ç›–å…¨é¢** - é—®é¢˜åº”è¦†ç›–æ–‡æœ¬çš„æ ¸å¿ƒæ¦‚å¿µã€é‡è¦ç»†èŠ‚å’Œå…³é”®ä¿¡æ¯
2. **å±‚æ¬¡åˆ†æ˜** - åŒ…å«ä¸åŒéš¾åº¦çº§åˆ«ï¼š
   - åŸºç¡€é—®é¢˜ï¼ˆæ˜¯ä»€ä¹ˆã€è°ã€ä½•æ—¶ã€ä½•åœ°ï¼‰
   - è¿›é˜¶é—®é¢˜ï¼ˆä¸ºä»€ä¹ˆã€å¦‚ä½•ã€åŸç†ï¼‰
   - æ·±åº¦é—®é¢˜ï¼ˆåˆ†æã€æ¯”è¾ƒã€åº”ç”¨ï¼‰
3. **è¡¨è¿°æ¸…æ™°** - é—®é¢˜æ˜ç¡®ã€æ— æ­§ä¹‰ã€ä¸“ä¸šæœ¯è¯­ä½¿ç”¨å‡†ç¡®
4. **ç‹¬ç«‹å®Œæ•´** - æ¯ä¸ªé—®é¢˜éƒ½èƒ½ç‹¬ç«‹ç†è§£ï¼Œä¸éœ€è¦é¢å¤–ä¸Šä¸‹æ–‡

### ç­”æ¡ˆè¦æ±‚
1. **å‡†ç¡®æ— è¯¯** - ç­”æ¡ˆå¿…é¡»å®Œå…¨åŸºäºæ–‡æœ¬å†…å®¹
2. **è¯¦ç»†å®Œæ•´** - æä¾›å……åˆ†çš„è§£é‡Šå’Œä¸Šä¸‹æ–‡
3. **ç»“æ„æ¸…æ™°** - å¤æ‚ç­”æ¡ˆä½¿ç”¨é€‚å½“çš„æ ¼å¼
4. **æ·±åº¦é€‚å½“** - æ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´ç­”æ¡ˆæ·±åº¦

### è¾“å‡ºè¦æ±‚
1. ä¸¥æ ¼JSONæ ¼å¼ï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ•°ç»„ï¼‰
2. æ¯ä¸ªQAå¯¹ç‹¬ç«‹å®Œæ•´
3. ä¸è¦é‡å¤æˆ–ç±»ä¼¼çš„é—®é¢˜
4. é—®é¢˜ç­”æ¡ˆè¦ä¸€ä¸€å¯¹åº”

## ğŸš¨ å…³é”®çº¦æŸ - å¿…é¡»ä¸¥æ ¼éµå®ˆ ğŸš¨
**ç»å¯¹ç¦æ­¢**ä½¿ç”¨ä»»ä½•markdownä»£ç å—æ ‡è®°ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
- ç¦æ­¢ä½¿ç”¨ ```json
- ç¦æ­¢ä½¿ç”¨ ```
- ç¦æ­¢ä½¿ç”¨ ```javascript
- ç¦æ­¢ä½¿ç”¨ä»»ä½•è¯­è¨€æ ‡è®°

**å¿…é¡»ç›´æ¥è¾“å‡ºçº¯JSONæ–‡æœ¬**ï¼Œä¸è¦æœ‰ä»»ä½•å‰ç¼€æˆ–åç¼€ã€‚

è¯·ç”Ÿæˆè¿™ {num_pairs} ä¸ªé—®ç­”å¯¹ã€‚ä¿æŒ{language}è¾“å‡ºã€‚"""

        user_prompt = f"""## å¾…å¤„ç†æ–‡æœ¬

ä»¥ä¸‹æ˜¯ä»æ–‡æ¡£ä¸­æå–çš„æ–‡æœ¬å†…å®¹ï¼Œè¯·ä»”ç»†åˆ†æå¹¶ç”Ÿæˆé—®ç­”å¯¹ï¼š

---
{text}
---

è¯·æŒ‰ç…§ä¸Šè¿°è´¨é‡æ ‡å‡†ï¼Œç”Ÿæˆ {num_pairs} ä¸ªé«˜è´¨é‡é—®ç­”å¯¹ã€‚

## è¾“å‡ºæ ¼å¼è¦æ±‚
ç›´æ¥è¾“å‡ºçº¯JSONæ•°ç»„ï¼Œä¸è¦æœ‰ä»»ä½•markdownæ ‡è®°ï¼š

[
  {{
    "instruction": "æ¸…æ™°æ˜ç¡®çš„é—®é¢˜",
    "input": "",
    "output": "è¯¦ç»†å‡†ç¡®çš„ç­”æ¡ˆ"
  }}
]

## ğŸš¨ ä¸¥æ ¼ç¦æ­¢ ğŸš¨
- âŒ ä¸è¦ä½¿ç”¨ ```json
- âŒ ä¸è¦ä½¿ç”¨ ```
- âŒ ä¸è¦ä½¿ç”¨ä»»ä½•ä»£ç å—
- âŒ ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—
- âŒ ä¸è¦æ·»åŠ ä»»ä½•å‰ç¼€æˆ–åç¼€

## âœ… å¿…é¡»éµå®ˆ âœ…
- âœ… ç›´æ¥è¾“å‡ºJSONæ•°ç»„
- âœ… ç¡®ä¿JSONæ ¼å¼æ­£ç¡®æœ‰æ•ˆ
- âœ… é—®é¢˜è¦†ç›–æ–‡æœ¬çš„æ ¸å¿ƒå†…å®¹
- âœ… ç­”æ¡ˆè¯¦ç»†ä¸”åŸºäºæ–‡æœ¬
        """
        # è®°å½•å¼€å§‹è°ƒç”¨LLM
        logger.info(f"å¼€å§‹ç”ŸæˆQAå¯¹ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")

        total_chars = len(text)

        # å°è¯•å¤šæ¬¡ç”Ÿæˆï¼Œé€‰æ‹©æœ€å¥½çš„ç»“æœ
        best_result = []
        for attempt in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
            try:
                print(
                    f"   ğŸ“¤ å‘é€è¯·æ±‚åˆ°LLM (æ–‡æœ¬ {total_chars} å­—ç¬¦, å°è¯• {attempt + 1}/3)...",
                    file=sys.stderr,
                    flush=True,
                )

                response = self.chat(
                    [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    json_mode=True,
                )

                response_chars = len(response)
                print(
                    f"   ğŸ“¥ æ”¶åˆ°LLMå“åº” ({response_chars} å­—ç¬¦)ï¼Œæ­£åœ¨è§£æJSON...",
                    file=sys.stderr,
                    flush=True,
                )

                pairs = self._extract_json(response)
                pairs_count = len(pairs)

                # éªŒè¯è´¨é‡
                if self._validate_qa_pairs(pairs, num_pairs):
                    best_result = pairs
                    print(
                        f"   âœ… æˆåŠŸ! ç”Ÿæˆ {pairs_count} ä¸ªQAå¯¹ (å°è¯• {attempt + 1}/3)",
                        file=sys.stderr,
                        flush=True,
                    )
                    break
                else:
                    print(
                        f"   âš ï¸ QAå¯¹éªŒè¯å¤±è´¥ï¼Œæ•°é‡ä¸è¶³ (å°è¯• {attempt + 1}/3)",
                        file=sys.stderr,
                        flush=True,
                    )

            except JSONParseError as e:
                print(
                    f"   âŒ JSONè§£æå¤±è´¥ (å°è¯• {attempt + 1}/3): {e}",
                    file=sys.stderr,
                    flush=True,
                )
            except Exception as e:
                print(
                    f"   âŒ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/3): {e}",
                    file=sys.stderr,
                    flush=True,
                )
                if attempt == 2:  # æœ€åä¸€æ¬¡å°è¯•
                    raise QAGenerationError(f"ç”ŸæˆQAå¯¹å¤±è´¥: {e}")
                continue

        # å¦‚æœè‡ªåŠ¨ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸºäºè§„åˆ™çš„fallback
        if not best_result:
            print(f"   âš ï¸ ä½¿ç”¨fallbackè§„åˆ™ç”ŸæˆQAå¯¹", file=sys.stderr, flush=True)
            logger.warning("ä½¿ç”¨fallbackç”Ÿæˆç®€å•QAå¯¹")
            best_result = self._generate_simple_qa(text, num_pairs)

        return best_result

    def _validate_qa_pairs(self, pairs: List[Dict], expected_count: int) -> bool:
        """
        éªŒè¯QAå¯¹è´¨é‡

        æ£€æŸ¥ï¼š
        - æ•°é‡æ˜¯å¦è¶³å¤Ÿ
        - æ ¼å¼æ˜¯å¦æ­£ç¡®
        - æ˜¯å¦æœ‰ç©ºå†…å®¹
        """
        if not pairs:
            return False

        if len(pairs) < expected_count // 2:
            return False

        for pair in pairs:
            if not isinstance(pair, dict):
                return False
            if not pair.get("instruction") or not pair.get("output"):
                return False

        return True

    def _extract_json(self, response: str) -> List[Dict[str, str]]:
        """
        ä»å“åº”ä¸­æå–JSON

        å°è¯•å¤šç§æ–¹å¼æå–ï¼š
        1. æ¸…ç†markdownæ ‡è®°åè§£æ
        2. ä»ä»£ç å—ä¸­æå–
        3. æŸ¥æ‰¾JSONæ•°ç»„
        """
        import re

        # é¦–å…ˆæ¸…ç†markdownä»£ç å—æ ‡è®°
        # å¤„ç† ```json\n[ å’Œ ```json [ ç­‰å„ç§æ ¼å¼
        cleaned = response.strip()
        cleaned = re.sub(r"^```(?:json)?\s*", "", cleaned)
        cleaned = re.sub(r"\s*```\s*$", "", cleaned)

        # æ–¹å¼1: è§£ææ¸…ç†åçš„å†…å®¹
        try:
            return json.loads(cleaned)
        except json.JSONDecodeError:
            pass

        # æ–¹å¼2: ä»ä»£ç å—ä¸­æå–ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
        json_match = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", response)
        if json_match:
            try:
                content = json_match.group(1).strip()
                # æ¸…ç†å¯èƒ½çš„ ```json æ®‹ç•™
                content = re.sub(r"^```(?:json)?\s*", "", content)
                content = re.sub(r"\s*```\s*$", "", content)
                return json.loads(content)
            except json.JSONDecodeError:
                pass

        # æ–¹å¼3: æŸ¥æ‰¾JSONæ•°ç»„ï¼ˆæ”¯æŒä¸å®Œæ•´çš„ä»£ç å—ï¼‰
        # åŒ¹é…ä» [ å¼€å§‹åˆ° ] ç»“æŸçš„å†…å®¹
        array_match = re.search(r"(\[[\s\S]*?\])(?:\s*$|\s*\n?\s*```)", response)
        if array_match:
            try:
                return json.loads(array_match.group(1))
            except json.JSONDecodeError:
                pass

        # æ–¹å¼4: æŸ¥æ‰¾æœ€åä¸€ä¸ªJSONæ•°ç»„ï¼ˆæœ€å¸¸è§çš„æƒ…å†µï¼‰
        all_arrays = re.findall(r"\[[\s\S]*?\]", response)
        for arr_str in reversed(all_arrays):  # ä»åå¾€å‰æ‰¾
            try:
                parsed = json.loads(arr_str)
                if isinstance(parsed, list) and len(parsed) > 0:
                    return parsed
            except json.JSONDecodeError:
                continue

        raise JSONParseError(f"æ— æ³•è§£æLLMå“åº”ä¸­çš„JSON:\nå“åº”å†…å®¹: {response[:500]}...")

    def _generate_simple_qa(self, text: str, num_pairs: int) -> List[Dict[str, str]]:
        """
        ç®€å•çš„fallback QAç”Ÿæˆ

        å½“LLMç”Ÿæˆå¤±è´¥æ—¶ä½¿ç”¨
        """
        import re

        # åˆ‡åˆ†æ–‡æœ¬ä¸ºå¥å­
        sentences = re.split(r"[ã€‚ï¼ï¼Ÿ\n]", text)
        sentences = [s.strip() for s in sentences if s.strip() and len(s) > 10]

        pairs = []
        for i, sent in enumerate(sentences[:num_pairs]):
            pairs.append(
                {"instruction": f"è¯·è§£é‡Šä»¥ä¸‹å†…å®¹", "input": "", "output": sent}
            )

        return pairs

    def generate_summarization(self, text: str, language: str = "zh") -> str:
        """ç”Ÿæˆé«˜è´¨é‡æ‘˜è¦"""
        lang_prompt = "ä¸­æ–‡" if language == "zh" else "English"

        print(
            f"   ğŸ“¤ æ­£åœ¨ç”Ÿæˆæ‘˜è¦ (æ–‡æœ¬ {len(text)} å­—ç¬¦)...",
            file=sys.stderr,
            flush=True,
        )

        response = self.chat(
            [
                {
                    "role": "system",
                    "content": f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬æ‘˜è¦ä¸“å®¶ã€‚
è¯·ç”¨{lang_prompt}ç”Ÿæˆä¸€æ®µç®€æ´è€Œå…¨é¢çš„æ‘˜è¦ã€‚
è¦æ±‚ï¼š
1. ä¿ç•™å…³é”®ä¿¡æ¯å’Œæ ¸å¿ƒè§‚ç‚¹
2. é€»è¾‘æ¸…æ™°ï¼Œç»“æ„å®Œæ•´
3. å­—æ•°é€‚ä¸­ï¼ˆ200-500å­—ï¼‰

è¯·ç›´æ¥è¾“å‡ºJSONæ ¼å¼ï¼ŒåŒ…å«summaryå­—æ®µï¼š""",
                },
                {"role": "user", "content": f"è¯·ä¸ºä»¥ä¸‹æ–‡æœ¬ç”Ÿæˆæ‘˜è¦ï¼š\n\n{text}"},
            ],
            json_mode=True,
        )

        print(f"   ğŸ“¥ æ‘˜è¦ç”Ÿæˆå®Œæˆ ({len(response)} å­—ç¬¦)", file=sys.stderr, flush=True)

        # æå–JSONä¸­çš„summaryå­—æ®µ
        try:
            response_data = json.loads(response)
            summary = response_data.get("summary", response).strip()
            print(f"   âœ… æˆåŠŸæå–æ‘˜è¦", file=sys.stderr, flush=True)
            return summary
        except json.JSONDecodeError:
            print(f"   âš ï¸ JSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å“åº”", file=sys.stderr, flush=True)
            return response.strip()

    def generate_conversation(
        self, text: str, num_turns: int = 3, language: str = "zh"
    ) -> List[Dict[str, str]]:
        """ç”Ÿæˆé«˜è´¨é‡å¯¹è¯æ•°æ®"""
        lang_prompt = "ä¸­æ–‡" if language == "zh" else "English"

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚
è¯·æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆä¸€æ®µè‡ªç„¶çš„å¯¹è¯ã€‚

è¦æ±‚ï¼š
1. å¯¹è¯è‡ªç„¶æµç•…ï¼ŒåƒçœŸå®å¯¹è¯
2. å†…å®¹åŸºäºæä¾›çš„æ–‡æ¡£
3. ä½“ç°æ–‡æ¡£çš„æ ¸å¿ƒä¿¡æ¯
4. {lang_prompt}è¾“å‡º
5. JSONæ•°ç»„æ ¼å¼

## ğŸš¨ ä¸¥æ ¼ç¦æ­¢ ğŸš¨
- âŒ ä¸è¦ä½¿ç”¨ ```json
- âŒ ä¸è¦ä½¿ç”¨ ```
- âŒ ä¸è¦ä½¿ç”¨ä»»ä½•ä»£ç å—
- âŒ ä¸è¦æ·»åŠ ä»»ä½•markdownæ ‡è®°

## âœ… å¿…é¡»éµå®ˆ âœ…
- âœ… ç›´æ¥è¾“å‡ºçº¯JSONæ•°ç»„
- âœ… ç¡®ä¿JSONæ ¼å¼æ­£ç¡®æœ‰æ•ˆ

å¯¹è¯æ ¼å¼ï¼ˆç›´æ¥è¾“å‡ºæ­¤æ ¼å¼ï¼Œä¸è¦ç”¨```åŒ…è£¹ï¼‰ï¼š
[
  {{"role": "user", "content": "ç”¨æˆ·é—®é¢˜"}},
  {{"role": "assistant", "content": "åŠ©æ‰‹å›ç­”"}}
]

è¯·ç”Ÿæˆ {num_turns} è½®å¯¹è¯ã€‚ç›´æ¥è¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦æœ‰ä»»ä½•å‰ç¼€æˆ–åç¼€ã€‚"""

        print(
            f"   ğŸ“¤ æ­£åœ¨ç”Ÿæˆå¯¹è¯ ({num_turns} è½®, æ–‡æœ¬ {len(text)} å­—ç¬¦)...",
            file=sys.stderr,
            flush=True,
        )

        response = self.chat(
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"åŸºäºä»¥ä¸‹å†…å®¹ç”Ÿæˆå¯¹è¯ï¼š\n\n{text}"},
            ],
            json_mode=True,
        )

        print(
            f"   ğŸ“¥ å¯¹è¯ç”Ÿæˆå®Œæˆ ({len(response)} å­—ç¬¦)ï¼Œæ­£åœ¨è§£æ...",
            file=sys.stderr,
            flush=True,
        )

        try:
            conversation = self._extract_json(response)
            print(
                f"   âœ… æˆåŠŸç”Ÿæˆ {len(conversation)} è½®å¯¹è¯",
                file=sys.stderr,
                flush=True,
            )
            return conversation
        except JSONParseError:
            # Fallback: è¿”å›ç®€å•æ ¼å¼
            print(f"   âš ï¸ å¯¹è¯è§£æå¤±è´¥ï¼Œä½¿ç”¨fallback", file=sys.stderr, flush=True)
            logger.warning("å¯¹è¯ç”ŸæˆJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨fallback")
            return [
                {"role": "user", "content": "è¯·ä»‹ç»ä¸€ä¸‹"},
                {"role": "assistant", "content": "å¥½çš„ï¼Œè®©æˆ‘æ¥ä»‹ç»..."},
            ]

    def batch_generate_qa(
        self, texts: List[str], num_pairs_per_text: int = 5, progress: bool = True
    ) -> List[Dict[str, str]]:
        """
        æ‰¹é‡ç”ŸæˆQAå¯¹

        ç‰¹ç‚¹ï¼š
        - æ¯ä¸ªæ–‡æœ¬ç‹¬ç«‹ç”Ÿæˆ
        - æ˜¾ç¤ºè¿›åº¦æ¡
        - è·³è¿‡ç©ºæ–‡æœ¬
        """
        from tqdm import tqdm

        all_pairs = []
        # è¿‡æ»¤ç©ºæ–‡æœ¬
        texts = [t for t in texts if t.strip()]

        iterator = tqdm(texts, desc="ğŸ”„ ç”Ÿæˆé«˜è´¨é‡QAå¯¹") if progress else texts

        for text in iterator:
            try:
                pairs = self.generate_qa_pairs(text, num_pairs_per_text)
                all_pairs.extend(pairs)
            except Exception as e:
                logger.warning(f"ç”Ÿæˆå¤±è´¥: {e}")
                continue

        return all_pairs


class CacheManager:
    """
    LLMå“åº”ç¼“å­˜ç®¡ç†å™¨

    ç”¨äºé¿å…é‡å¤è°ƒç”¨LLMï¼ŒèŠ‚çœæˆæœ¬

    ç‰¹æ€§ï¼š
    - ç¼“å­˜æ¸…ç†æœºåˆ¶ï¼ˆå¤§å°é™åˆ¶ã€æ—¶é—´é™åˆ¶ï¼‰
    - çº¿ç¨‹å®‰å…¨
    - è·¨å¹³å°æ”¯æŒ
    """

    def __init__(
        self,
        cache_dir: str = "./data/cache",
        max_size: int = DEFAULT_CACHE_MAX_SIZE,
        max_age: int = DEFAULT_CACHE_MAX_AGE,
    ):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•° (é»˜è®¤ 1000)
            max_age: ç¼“å­˜æœ€å¤§å­˜æ´»æ—¶é—´ï¼Œç§’ (é»˜è®¤ 24å°æ—¶)
        """
        self.cache_dir = Path(cache_dir)
        self.max_size = max_size
        self.max_age = max_age
        self._ensure_cache_dir()

    def _ensure_cache_dir(self):
        """ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨"""
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_cache_key(self, text: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        import hashlib

        content = text + str(sorted(kwargs.items()))
        return hashlib.md5(content.encode()).hexdigest()

    def _get_cache_file(self, key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{key}.json"

    def _get_cache_info_file(self, key: str) -> Path:
        """è·å–ç¼“å­˜ä¿¡æ¯æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{key}.info"

    def _get_file_age(self, file_path: Path) -> float:
        """è·å–æ–‡ä»¶å¹´é¾„ï¼ˆç§’ï¼‰"""
        try:
            return time.time() - file_path.stat().st_mtime
        except OSError:
            return float("inf")

    def _save_cache_info(self, key: str, metadata: Optional[Dict] = None):
        """ä¿å­˜ç¼“å­˜å…ƒä¿¡æ¯"""
        info_file = self._get_cache_info_file(key)
        info = {"created_at": time.time(), "key": key, **(metadata or {})}
        try:
            with open(info_file, "w") as f:
                json.dump(info, f)
        except Exception as e:
            logger.warning(f"ä¿å­˜ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")

    def get(self, text: str, **kwargs) -> Optional[str]:
        """è·å–ç¼“å­˜

        Args:
            text: ç¼“å­˜çš„æ–‡æœ¬
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            ç¼“å­˜çš„å“åº”ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        key = self._get_cache_key(text, **kwargs)
        cache_file = self._get_cache_file(key)
        info_file = self._get_cache_info_file(key)

        if not cache_file.exists():
            return None

        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if info_file.exists():
            try:
                with open(info_file, "r") as f:
                    info = json.load(f)
                created_at = info.get("created_at", 0)
                if time.time() - created_at > self.max_age:
                    # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                    self._delete_cache(key)
                    return None
            except Exception:
                pass

        try:
            with open(cache_file, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            return None

    def set(self, text: str, response: str, **kwargs):
        """è®¾ç½®ç¼“å­˜

        Args:
            text: ç¼“å­˜çš„æ–‡æœ¬
            response: ç¼“å­˜çš„å“åº”
            **kwargs: å…¶ä»–å‚æ•°
        """
        key = self._get_cache_key(text, **kwargs)
        cache_file = self._get_cache_file(key)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç¼“å­˜
        self._cleanup_if_needed()

        try:
            with open(cache_file, "w", encoding="utf-8") as f:
                f.write(response)
            self._save_cache_info(key, {"text_length": len(text)})
        except Exception as e:
            logger.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def _delete_cache(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        cache_file = self._get_cache_file(key)
        info_file = self._get_cache_info_file(key)

        try:
            if cache_file.exists():
                cache_file.unlink()
            if info_file.exists():
                info_file.unlink()
        except Exception as e:
            logger.warning(f"åˆ é™¤ç¼“å­˜å¤±è´¥: {e}")

    def _cleanup_if_needed(self):
        """å¿…è¦æ—¶æ¸…ç†ç¼“å­˜"""
        try:
            # ç»Ÿè®¡ç¼“å­˜æ•°é‡
            cache_files = list(self.cache_dir.glob("*.json"))

            if len(cache_files) < self.max_size:
                return

            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜
            cache_with_age = []
            for cache_file in cache_files:
                key = cache_file.stem
                info_file = self._get_cache_info_file(key)

                if info_file.exists():
                    try:
                        with open(info_file, "r") as f:
                            info = json.load(f)
                        created_at = info.get("created_at", 0)
                        cache_with_age.append((cache_file, created_at))
                    except Exception:
                        cache_with_age.append((cache_file, 0))
                else:
                    cache_with_age.append((cache_file, 0))

            # æŒ‰æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„
            cache_with_age.sort(key=lambda x: x[1])
            num_to_delete = len(cache_files) - self.max_size + 100

            for cache_file, _ in cache_with_age[:num_to_delete]:
                key = cache_file.stem
                self._delete_cache(key)
                logger.debug(f"æ¸…ç†ç¼“å­˜: {key}")

        except Exception as e:
            logger.warning(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")

    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        try:
            for cache_file in self.cache_dir.glob("*.json"):
                cache_file.unlink()
            for info_file in self.cache_dir.glob("*.info"):
                info_file.unlink()
            logger.info(f"å·²æ¸…ç©ºç¼“å­˜ç›®å½•: {self.cache_dir}")
        except Exception as e:
            logger.error(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")
            raise CacheError(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            info_files = list(self.cache_dir.glob("*.info"))

            total_size = sum(f.stat().st_size for f in cache_files if f.exists())

            # è®¡ç®—ç¼“å­˜å¹´é¾„
            ages = []
            for info_file in info_files:
                try:
                    with open(info_file, "r") as f:
                        info = json.load(f)
                    created_at = info.get("created_at", 0)
                    if created_at:
                        ages.append(time.time() - created_at)
                except Exception:
                    pass

            avg_age = sum(ages) / len(ages) if ages else 0

            return {
                "cache_count": len(cache_files),
                "total_size_bytes": total_size,
                "total_size_mb": total_size / 1024 / 1024,
                "max_size": self.max_size,
                "max_age_seconds": self.max_age,
                "avg_age_seconds": avg_age,
                "cache_dir": str(self.cache_dir),
            }
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {}


"""
LLM è°ƒç”¨æ¨¡å—

æœ¬æ¨¡å—æä¾› OpenAI API é›†æˆå’Œé«˜å“è´¨è®­ç»ƒæ•°æ®ç”ŸæˆåŠŸèƒ½ã€‚

## ä¸»è¦åŠŸèƒ½

### LLMClient - LLM å®¢æˆ·ç«¯

æä¾›ä¸ OpenAI API çš„äº¤äº’æ¥å£ï¼Œæ”¯æŒï¼š
- åŸºç¡€å¯¹è¯åŠŸèƒ½
- QA å¯¹æ‰¹é‡ç”Ÿæˆ
- æ–‡æœ¬æ‘˜è¦ç”Ÿæˆ
- å¯¹è¯æ•°æ®ç”Ÿæˆ
- å“åº”ç¼“å­˜

### CacheManager - ç¼“å­˜ç®¡ç†å™¨

æä¾› LLM å“åº”ç¼“å­˜åŠŸèƒ½ï¼Œæ”¯æŒï¼š
- è‡ªåŠ¨ç¼“å­˜ç®¡ç†
- ç¼“å­˜å¤§å°é™åˆ¶
- ç¼“å­˜è¿‡æœŸæ¸…ç†
- ç¼“å­˜ç»Ÿè®¡

## ä½¿ç”¨ç¤ºä¾‹

```python
from src.llm import LLMClient, CacheManager

# åˆ›å»º LLM å®¢æˆ·ç«¯
client = LLMClient(
    api_key="your-api-key",
    model="gpt-4o",
    temperature=0.3
)

# å‘é€å¯¹è¯
response = client.chat([
    {"role": "user", "content": "ä½ å¥½ï¼"}
])
print(response)

# ç”Ÿæˆ QA å¯¹
qa_pairs = client.generate_qa_pairs(
    text="è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬...",
    num_pairs=5,
    language="zh"
)

# ä½¿ç”¨ç¼“å­˜
cache = CacheManager(
    cache_dir="./data/cache",
    max_size=1000,
    max_age=86400  # 24å°æ—¶
)

# æ£€æŸ¥ç¼“å­˜
cached = cache.get(text)
if not cached:
    response = client.generate_qa_pairs(text)
    cache.set(text, response)
```

## å¼‚å¸¸å¤„ç†

æœ¬æ¨¡å—å®šä¹‰äº†ä»¥ä¸‹è‡ªå®šä¹‰å¼‚å¸¸ï¼š

- `LLMError` - LLM è°ƒç”¨é”™è¯¯åŸºç±»
- `QAGenerationError` - QA å¯¹ç”Ÿæˆé”™è¯¯
- `JSONParseError` - JSON è§£æé”™è¯¯
- `CacheError` - ç¼“å­˜æ“ä½œé”™è¯¯

```python
from src.llm import LLMClient, QAGenerationError, JSONParseError

client = LLMClient()

try:
    qa_pairs = client.generate_qa_pairs(text)
except QAGenerationError as e:
    print(f"QA ç”Ÿæˆå¤±è´¥: {e}")
except JSONParseError as e:
    print(f"JSON è§£æå¤±è´¥: {e}")
```

## æ€§èƒ½ä¼˜åŒ–

1. **ç¼“å­˜ç­–ç•¥**
   - é»˜è®¤ç¼“å­˜ 1000 æ¡
   - é»˜è®¤è¿‡æœŸæ—¶é—´ 24 å°æ—¶
   - è‡ªåŠ¨æ¸…ç†æ—§ç¼“å­˜

2. **æ‰¹å¤„ç†**
   - ä½¿ç”¨ `batch_generate_qa()` æ‰¹é‡ç”Ÿæˆ
   - è‡ªåŠ¨è¿‡æ»¤ç©ºæ–‡æœ¬

3. **æ¸©åº¦è®¾ç½®**
   - é»˜è®¤æ¸©åº¦ 0.2ï¼Œç¡®ä¿è¾“å‡ºç¨³å®š
   - å¯æ ¹æ®éœ€è¦è°ƒæ•´

## æ³¨æ„äº‹é¡¹

- éœ€è¦æœ‰æ•ˆçš„ OpenAI API Key
- API è°ƒç”¨ä¼šè®¡è´¹ï¼Œè¯·æ³¨æ„æˆæœ¬æ§åˆ¶
- å»ºè®®è®¾ç½®åˆç†çš„ max_tokens é™åˆ¶
- å¤§æ–‡æœ¬ä¼šè‡ªåŠ¨åˆ†å—å¤„ç†
"""

__all__ = [
    "LLMClient",
    "CacheManager",
    "LLMError",
    "QAGenerationError",
    "JSONParseError",
    "CacheError",
]
